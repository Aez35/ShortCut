#!/usr/bin/env python
version = '0.1'

import re, gzip
import argparse, shutil, subprocess
from subprocess import Popen, PIPE, STDOUT
import os, glob
from pathlib import Path
import csv, sys, time
from csv import writer
import rpy2.robjects as robjects
robjects.r('library(ggplot2)')
robjects.r('library(tidyverse)')

print("Checking required modules...")
req_packs=["bowtie","samtools","RNAfold","cutadapt"]
for pack in req_packs:
        path = shutil.which(pack)
        if path is not None:
            print('Requires package {0} : {1}'.format(pack,path))
        else:
            msg = 'Requires package {0} : Not found!'.format(pack)
            sys.exit(msg)


ap = argparse.ArgumentParser()

ap.add_argument('-fastq',nargs='*',required=True,help='One or more fastq alignment files')
ap.add_argument("-n", help="Results file name")
ap.add_argument("-threads", help="Specify number of threads for samtools", default = 1)
ap.add_argument("-kingdom", required=True,choices=["plant","animal"],help="Specify animal or plant")
ap.add_argument("-annotate",help="Specify whether you want ShortStack to annotate",nargs='?', const='')
ap.add_argument("-out", help="output directory",default="plotrim_output")
ap.add_argument('-genome',help='Genome for annotation')
ap.add_argument('-known_mirnas',help='FASTA-formatted file of known mature miRNA sequences')
ap.add_argument("-ssout", help="output directory",default="Shortstack_output")
ap.add_argument("-trimkey", help="Abundant miRNA used to find adapters for trimming with option -autotrim")
ap.add_argument("-dn_mirna", help="De novo miRNA search in ShortStack")
args = ap.parse_args()

#print log
print("--------")
print("sRNATrim version " + version)
print("Options:")
print("     'Threads' " + str(args.threads))
print("     'Kingdom' "+ args.kingdom)
print("     'Output directory' "+ args.out+"/")
if args.fastq is not None:
    print("     'Fastqs' " +str(args.fastq))
if args.annotate is not None:
    print("     'Annotate sRNAs' yes")
    print("     'Genome' " +str(args.genome))
    print("     'known_mirnas' " +str(args.known_mirnas))
    if args.dn_mirna == True:
        print("     'denovo miRNAs' " +str(args.known_mirnas))
    print("     'ssout' " +str(args.ssout))

print("--------")

if args.annotate is True:
    req_packs=["ShortStack"]
    for pack in req_packs:
        path = shutil.which(pack)
        if path is not None:
            print('Requires package {0} : {1}'.format(pack,path))
        else:
            msg = 'Requires package {0} : Not found!'.format(pack)
            sys.exit(msg)

path=args.out
isExist = os.path.exists(path)
if isExist==True:
    msg = ("Output directory '" + args.out + "/' already exists. Please assign a new output directory using option '-out'.")
    sys.exit(msg)

if args.annotate is None and args.genome is not None:
        msg="Error: To annotate using ShortStack, please include the option '-annotate'."
        sys.exit(msg)
#_____________ Functions ______________
def run(cmd) :
#Run subprocess
    proc = subprocess.call(cmd, shell=True,stdout=subprocess.DEVNULL,stderr=subprocess.STDOUT)

def process_fastqs(fastqs, keydna, args):
    count = 0  # Initialize count at the start of the function

    for fastq in fastqs:
        print("Detecting adapter for " + fastq + " with key "  + keydna)
        if not os.path.exists(fastq):
            sys.exit(f"Error: File {fastq} does not exist. Please check the path.")

        if fastq.endswith(".gz"):
            cmd = (
                f"gzip -dc {fastq} | awk -v target='{keydna}' '{{idx = index($0, target); if (idx) print substr($0, idx + length(target),20)}}' | "
                "uniq -c | sort -nr | head -n1 | awk '{print $2}'"
            )
        else:
            cmd = (
                f"awk -v target='{keydna}' '{{idx = index($0, target); if (idx) print substr($0, idx + length(target),20)}}' {fastq} | "
                "uniq -c | sort -nr | head -n1 | awk '{print $2}'"
            )

        try:
            output = subprocess.check_output(cmd, shell=True, text=True).strip()
        except subprocess.CalledProcessError as e:
            sys.exit(f"Error while processing {fastq}: {e.output}")

        if "G" not in output:
            print("No adapter detected. Copying untrimmed file to trimmedLibraries instead.")
            count += 1  # Correct increment

            head, tail = os.path.split(fastq)
            tfile = os.path.join('trimmedLibraries', f"{tail}")
            shutil.copy(fastq, tfile)
            continue
        else:
            print(f"Adapter detected: {output}")

        head, tail = os.path.split(fastq)
        tfile = os.path.join('trimmedLibraries', f"t_{tail}")
        report_file = os.path.join('trimmedLibraries', f"{tail}_cutadapt_report.txt")

        if fastq.endswith(".gz"):
            cmd = (
                f"gzip -dc {fastq} | cutadapt -j {args.threads} -a {output} -o {tfile} -m 12 -"
            )
        else:
            cmd = f"cutadapt -j {args.threads} -a {output} -o {tfile} -m 12 {fastq}"

        try:
            result = subprocess.run(cmd, shell=True, text=True, capture_output=True)
            with open(report_file, "w") as rf:
                rf.write(result.stdout)
        except Exception as e:
            sys.exit(f"Error trimming {fastq}: {e}")

    return count

def summarize_cutadapt_reports(trimmed_dir='trimmedLibraries', output_csv='trimming_summary.csv'):
    summary = {}

    for filename in os.listdir(trimmed_dir):
        if filename.endswith("_cutadapt_report.txt"):
            sample = filename.replace("_cutadapt_report.txt", "")
            filepath = os.path.join(trimmed_dir, filename)
            
            with open(filepath) as f:
                content = f.read()

            total_reads=re.search(r"Total reads processed:\s+([\d,]+)", content)
            if total_reads:
                total_count = total_reads.group(1).replace(",", "")


            # Extract "Reads with adapters"
            match_adapters = re.search(r"Reads with adapters:\s+([\d,]+) \(([\d.]+)%\)", content)
            if match_adapters:
                adapters_count = match_adapters.group(1).replace(",", "")
                adapters_percent = match_adapters.group(2) + "%"
            else:
                adapters_count = adapters_percent = "N/A"

            # Extract "Reads written"
            match_written = re.search(r"Reads written \(passing filters\):\s+([\d,]+) \(([\d.]+)%\)", content)
            if match_written:
                written_count = match_written.group(1).replace(",", "")
                written_percent = match_written.group(2) + "%"
            else:
                written_count = written_percent = "N/A"

            summary[sample] = {
                "Reads with adapters": adapters_count,
                "% Reads with adapters": adapters_percent,
                "Reads written (passing filters)": written_count,
                "% Reads written": written_percent,
                "Total reads": total_count
            }

    # Transpose into a dataframe-like CSV structure
    metrics = ["Reads with adapters", "% Reads with adapters", 
               "Reads written (passing filters)", "% Reads written", "Total reads"]

    with open(output_csv, "w", newline="") as csvfile:
        writer = csv.writer(csvfile)
        header = ["Metric"] + list(summary.keys())
        writer.writerow(header)
        
        for metric in metrics:
            row = [metric]
            for sample in summary:
                row.append(summary[sample].get(metric, "N/A"))
            writer.writerow(row)
    
    print(f"Cutadapt summary written to {output_csv}")

def DNAcheck(dna):
    """
    Check whether a DNA/RNA sequence contains only valid nucleotides (A, T, G, C, U).

    Parameters:
        sequence (str): DNA/RNA sequence to validate.

    Returns:
        int: 2 if the sequence is valid, 1 otherwise.
    """
#Check that all characters in provided sequences are ATGCU
    y = dna.upper()
    if re.match("^[ATGCU]+$", y):
        return(2)
    else:
        return(1)

def get_distribution_from_trimmedLibraries(trimmedLibraries):
    # Get a list of all FASTQ and gzipped FASTQ files in the directory
    fastq_files = [
        os.path.join(trimmedLibraries, f)
        for f in os.listdir(trimmedLibraries)
        if f.endswith('.fastq') or f.endswith('.fastq.gz')
    ]
    
    if not fastq_files:
        print("No FASTQ files found in the trimmedLibraries.")
        return

    # Dictionary to store read length distributions
    distributions = {}

    for fastq_file in fastq_files:
        length_count = {}

        # Open normally if .fastq, else use gzip for .fastq.gz
        open_func = gzip.open if fastq_file.endswith('.gz') else open

        with open_func(fastq_file, 'rt') as f:
            for i, line in enumerate(f):
                if i % 4 == 1:  # Sequence lines (2nd line in every FASTQ entry)
                    read_length = len(line.strip())
                    length_count[read_length] = length_count.get(read_length, 0) + 1

        distributions[fastq_file] = length_count

    # Find the union of all read lengths across all files
    all_lengths = sorted({length for dist in distributions.values() for length in dist})

    # Prepare CSV data
    csv_data = [['Read Length'] + [os.path.basename(file) for file in fastq_files]]  # Header row

    for length in all_lengths:
        row = [length]  # First column is the read length
        for file in fastq_files:
            row.append(distributions[file].get(length, 0))
        csv_data.append(row)

    # Write to CSV file
    output_csv = 'read_length_distribution.csv'
    with open(output_csv, 'w', newline='') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerows(csv_data)


def run_ss(t_fastq_list, threads, genome, known_mirnas):
    print("Annotating sRNAs in " + str(args.known_mirnas))
    if args.dn_mirna == True:
        print("Conducting de novo annotation of sRNAs...")

        command=(f"ShortStack --genomefile ../{genome} --threads {threads} --readfile {t_fastq_list}* --dn_mirna --known_miRNAs ../{known_mirnas}")
        run(command)
    else:
        command = f"ShortStack --genomefile ../{genome} --threads {threads} --readfile {t_fastq_list}* --known_miRNAs ../{known_mirnas}"
        # Open process and stream output in real-time
    # Use Popen for real-time output streaming
    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, bufsize=1, universal_newlines=True)

    # Print output line by line in real time
    for line in process.stdout:
        print(line, end="")  # Print and flush each line
        sys.stdout.flush()   # Ensure immediate printing

    # Print error output if any
    for line in process.stderr:
        print(line, end="", file=sys.stderr)
        sys.stderr.flush()

    process.wait()  # Ensure the process completes

def count_reads(filepath):
    """Count reads in a FASTQ or FASTQ.GZ file (1 read = 4 lines)"""
    open_func = gzip.open if filepath.endswith('.gz') else open
    with open_func(filepath, 'rt') as f:
        return sum(1 for _ in f) // 4

def get_fastq_files(directory):
    """Return list of .fastq, .fastq.gz, .fq, .fq.gz files in directory"""
    valid_extensions = ('.fastq', '.fastq.gz', '.fq', '.fq.gz')
    return [f for f in os.listdir(directory) if f.endswith(valid_extensions)]

def generate_library_size_csv(directory, output_csv="library_sizes.csv"):
    fastq_files = get_fastq_files(directory)
    if not fastq_files:
        print("No FASTQ files found in directory.")
        return

    with open(output_csv, 'w', newline='') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(["Library", "ReadCount"])

        for filename in fastq_files:
            filepath = os.path.join(directory, filename)
            read_count = count_reads(filepath)
            writer.writerow([filename, read_count])

#_________ run ____________
def main():
            subprocess.call(["mkdir",args.out])
            os.chdir(args.out)

            fastqs = ['../' + item for item in args.fastq]

            print("_____________________________")
            print(" ")
            print("Trimming adapters...")
            #If no key provided, set key according to kingdom.
            if args.trimkey is None:
                subprocess.call(["mkdir","trimmedLibraries"])
                if args.kingdom == 'plant':
                    #ath-miR166a
                    print("No key provided for trimming.")
                    key="UCGGACCAGGCUUCAUUCCCC"
                    print("     trimkey used for discovering adapter sequence: "+key)
                else:
                    #hsa-let-7a
                    print("No key provided for trimming.")
                    key="UGAGGUAGUAGGUUGUAUAGUU"
                    print("     trimkey used for discovering adapter sequence: " + key)
            else:
                subprocess.call(["mkdir","trimmedLibraries"])
                key=args.trimkey
            #Change key to uppercase and to DNA
            key=key.upper()
            keydna=key.translate(str.maketrans("uU", "tT"))

            key_check=DNAcheck(keydna)
            if key_check ==1:
                sys.exit("Error! Key for trimming adapters has characters besides A, T, G, C, or U!")
            if (len(key) < 20) or (len(key) > 30):
                sys.exit("Trim key must be between 20 and 30 letters")

            #pre-trimmed lib count  
            count=0
  
            #Trim adapters
            count = process_fastqs(fastqs, keydna, args)

            print("Adapter trimming complete. ✅")

            get_distribution_from_trimmedLibraries("trimmedLibraries/")

            # library size graph:
            #R lib distribution
            r_script1 = """

            # Load data
            df <- read_csv("trimming_summary.csv",show_col_types = FALSE)

            # Pivot into long format, including Total reads
            df_long <- df %>%
            filter(Metric %in% c( "Reads with adapters", "Reads written (passing filters)","Total reads")) %>%
            pivot_longer(-Metric, names_to = "Library", values_to = "Count") %>%
            mutate(
                Count = as.numeric(Count),
                Metric = factor(
                Metric,
                levels = c("Total reads","Reads with adapters", "Reads written (passing filters)")
                )
            )
                
            # Pivot wider to get totals for each library
            totals <- df_long %>%
            filter(Metric == "Total reads") %>%
            select(Library, Total = Count)

            # Join with long data and compute percentage
            df_labeled <- df_long %>%
            left_join(totals, by = "Library") %>%
            mutate(Percent = round(100 * Count / Total, 1),
                    Label = paste0(Percent, "%"))

            # Extract % Reads written to use as labels
            percent_labels <- df %>%
            filter(Metric == "% Reads written") %>%
            pivot_longer(-Metric, names_to = "Library", values_to = "Percent")

            # Plot function
            lib_plot <- function(data) {
            ggplot(df_labeled, aes(x = Library, y = Count, fill = Metric)) +
                geom_bar(stat = "identity", position = position_dodge(width = 0.7), 
                        color = "black", width = 0.6, alpha = 0.85) +
                geom_text(
                    aes(label = Label),
                    position = position_dodge(width = 0.7),
                    vjust = -0.5,
                    size = 3,
                    fontface = "bold"
                ) +
                scale_fill_manual(values = c(
                    "Total reads" = "grey80",
                    "Reads written (passing filters)" = "steelblue",
                    "Reads with adapters" = "lightblue"
                )) +
                scale_y_continuous(labels = scales::comma, expand = expansion(mult = c(0, 0.1))) +
                labs(
                    title = "Cutadapt Summary",
                    x = "Library",
                    y = "Read Count",
                    fill = "Read Type"
                ) +
                theme_minimal() +
                theme(axis.text.x = element_text(angle = 45, hjust = 1))
            }

            # Generate and save the plot
            plot_obj <- lib_plot(df_labeled)
            ggsave("Cutadapt_summary.png", plot = plot_obj, width = 10, height = 7, dpi = 300, bg = "white")
            """
            if count < len(args.fastq):
                summarize_cutadapt_reports()
                print("Libraries trimmed: " + str(count))

                # Generate R plot
                robjects.r(r_script1)
                print("Cutadapt summary generated. ✅")

                
            # Only continue if some libraries were actually trimmed
            get_distribution_from_trimmedLibraries("trimmedLibraries/",)

            
            #Create read distribution plots            
            r_script="""

            file_path <- "read_length_distribution.csv"

            # Load and filter data
            data <- read.csv(file_path)
            data_filt <- data[data$Read.Length < 51, ]

            # Get list of library names (excluding Read.Length column)
            libraries <- colnames(data_filt)[-1]

            # Start PDF device
            pdf("Read_distribution.pdf", width = 10, height = 6, bg = "white")

            # Loop through libraries and plot each one
            for (lib in libraries) {
            df_single <- data_filt %>%
                select(Read.Length, all_of(lib)) %>%
                rename(Count = all_of(lib))

            plot_obj <- ggplot(df_single, aes(x = Read.Length, y = Count)) +
                geom_line(color = "steelblue", linewidth = 1) +
                geom_point(color = "steelblue", size = 2) +  # Add points to each x
                theme_minimal() +
                labs(
                title = paste("Read Length Distribution:", lib),
                x = "Read Length",
                y = "Count"
                ) +
                scale_x_continuous(
                breaks = seq(min(df_single$Read.Length), max(df_single$Read.Length), by = 1)
                ) +
                theme(
                legend.position = "none",
                panel.grid.minor.x = element_blank(), # Remove minor x gridlines
                panel.grid.major.x = element_line(color = "grey80") # Keep only integer lines
                )

            print(plot_obj)  # Each plot gets its own page
            }

            dev.off()

            """

            robjects.r(r_script)
            print("Read distribution plot generated. ✅")

            generate_library_size_csv("trimmedLibraries",output_csv="library_sizes.csv")

            r_script_libsize = """
            library(tidyverse)

            # Define your directory
            libCounts<- read.csv("library_sizes.csv")

            libCounts <- libCounts %>%
            mutate(Library = factor(Library, levels = Library[order(ReadCount)]),
                    ReadCount_shadow = ReadCount * 0.90)  # Adjust depth of the "3D" effect

            plot_obj<-ggplot(libCounts) +
            # Shadow (slightly offset to bottom-right)
            geom_col(aes(x = Library, y = ReadCount_shadow), fill = "grey30", width = 0.6) +
            # Main bar
            geom_col(aes(x = Library, y = ReadCount), fill = "steelblue", width = 0.6) +
            # Labels
            geom_text(aes(x = Library, y = ReadCount, label = format(ReadCount, big.mark = ",")),
                        vjust = -0.5, size = 3, fontface = "bold") +
            labs(
                title = "Read Counts per Library",
                x = "Library",
                y = "Number of Reads"
            ) +
            theme_minimal(base_size = 13) +
            theme(axis.text.x = element_text(angle = 45, hjust = 1))

            # Generate and save the plot
            ggsave("Library_summary.png", plot = plot_obj, width = 10, height = 7, dpi = 300, bg = "white")
            """

            robjects.r(r_script_libsize)
            print("Library size plot generated. ✅")


            t_fastq_files = "trimmedLibraries/"
            if args.annotate is not None:
                run_ss(t_fastq_files,args.threads,args.genome,args.known_mirnas)
            

            cmd = f"rm -rf trimmedLibraries/*.txt"
            os.system(cmd)
            cmd = f"rm trimming_summary.csv read_length_distribution.csv"
            os.system(cmd)
            cmd = f"rm library_sizes.csv"
            os.system(cmd)

if __name__ == "__main__":
    main()

